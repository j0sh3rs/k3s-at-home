---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: mimir
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://grafana.github.io/helm-charts
      chart: mimir-distributed
      version: 5.4.0-weekly.290
      sourceRef:
        kind: HelmRepository
        name: grafana-charts
        namespace: flux-system
      interval: 5m
  install:
    crds: CreateReplace
  upgrade:
    crds: CreateReplace
    force: true
  valuesFrom:
    - kind: Secret
      name: mimir-secrets
      valuesKey: s3AccessKey
      targetPath: mimir.structuredConfig.common.storage.s3.access_key_id
    - kind: Secret
      name: mimir-secrets
      valuesKey: s3SecretKey
      targetPath: mimir.structuredConfig.common.storage.s3.secret_access_key
    # - kind: Secret
    #   name: mimir-secrets
    #   valuesKey: s3AccessKey
    #   targetPath: tempo.storage.trace.s3.access_key
    # - kind: Secret
    #   name: mimir-secrets
    #   valuesKey: s3SecretKey
    #   targetPath: tempo.storage.trace.s3.secret_key
  values:
    grafana:
      enabled: false
    mimir:
      nameOverride: mimir
      fullnameOverride: mimir
      structuredConfig:
        common:
          storage:
            backend: s3
            s3:
              endpoint: &s3_endpoint s3.68cc.io
              region: &s3_region us-east-1
        blocks_storage:
          s3:
            bucket_name: mimir-blocks
        alertmanager_storage:
          s3:
            bucket_name: mimir-alertmanager
        ruler_storage:
          s3:
            bucket_name: mimir-ruler
        limits:
          compactor_blocks_retention_period: 60d
      image:
        pullPolicy: Always
      alertmanager:
        enabled: false
        persistentVolume:
          enabled: true
        replicas: 1
        resources:
          limits:
            memory: 1.4Gi
            cpu: 1.5
          requests:
            cpu: 500m
            memory: 1Gi
        statefulSet:
          enabled: true
      compactor:
        persistentVolume:
          size: 20Gi
        resources:
          limits:
            memory: 2.1Gi
          requests:
            cpu: 1
            memory: 1.5Gi
      distributor:
        replicas:
        resources:
          limits:
            memory: 5.7Gi
            cpu: 1
          requests:
            cpu: 500m
            memory: 4Gi
      ingester:
        statefulSet:
          enabled: false
        persistentVolume:
          size: 50Gi
        replicas: 1
        resources:
          limits:
            memory: 12Gi
            cpu: 1.5
          requests:
            cpu: 500m
            memory: 4Gi
        topologySpreadConstraints: {}
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: target # support for enterprise.legacyLabels
                      operator: In
                      values:
                        - ingester
                topologyKey: 'kubernetes.io/hostname'
              - labelSelector:
                  matchExpressions:
                    - key: app.kubernetes.io/component
                      operator: In
                      values:
                        - ingester
                topologyKey: 'kubernetes.io/hostname'
        zoneAwareReplication:
          topologyKey: 'kubernetes.io/hostname'
      admin-cache:
        enabled: true
        replicas: 1
      chunks-cache:
        enabled: true
        replicas: 1
      index-cache:
        enabled: true
        replicas: 1
      metadata-cache:
        enabled: true
      results-cache:
        enabled: true
        replicas: 1
      minio:
        enabled: false
      overrides_exporter:
        replicas: 1
        resources:
          limits:
            memory: 128Mi
          requests:
            cpu: 100m
            memory: 128Mi
      querier:
        replicas: 1
        resources:
          limits:
            memory: 5.6Gi
          requests:
            cpu: 1
            memory: 4Gi
      query_frontend:
        replicas: 1
        resources:
          limits:
            memory: 2.8Gi
            cpu: 1.5
          requests:
            cpu: 500m
            memory: 2Gi
      ruler:
        replicas: 1
        resources:
          limits:
            memory: 2.8Gi
            cpu: 1.5
          requests:
            cpu: 500m
            memory: 2Gi
      store_gateway:
        persistentVolume:
          size: 50Gi
        replicas: 1
        resources:
          limits:
            memory: 2.1Gi
            cpu: 1.5
          requests:
            cpu: 500m
            memory: 1.5Gi
        topologySpreadConstraints: {}
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: target # support for enterprise.legacyLabels
                      operator: In
                      values:
                        - store-gateway
                topologyKey: 'kubernetes.io/hostname'

              - labelSelector:
                  matchExpressions:
                    - key: app.kubernetes.io/component
                      operator: In
                      values:
                        - store-gateway
                topologyKey: 'kubernetes.io/hostname'
        zoneAwareReplication:
          topologyKey: 'kubernetes.io/hostname'
      nginx:
        enabled: false
      # Grafana Enterprise Metrics feature related
      admin_api:
        replicas: 1
        resources:
          limits:
            memory: 128Mi
          requests:
            cpu: 100m
            memory: 64Mi
      gateway:
        replicas: 1
        resources:
          limits:
            memory: 731Mi
          requests:
            cpu: 1
            memory: 512Mi
    loki:
      enabled: false
      nameOverride: loki
      fullnameOverride: loki
      loki:
        structuredConfig:
          auth_enabled: false
          analytics:
            reporting_enabled: false
          chunk_store_config:
            cache_lookups_older_than: 0s
          compactor:
            working_directory: /var/loki/compactor
          common:
            compactor_address: http://loki-compactor:3100
            storage:
              s3:
                endpoint: *s3_endpoint
                s3forcepathstyle: true
                region: *s3_region
                bucketnames: loki-data
          distributor:
            ring:
              kvstore:
                store: memberlist
          frontend:
            compress_responses: true
            log_queries_longer_than: 5s
            tail_proxy_url: http://loki-querier:3100
          frontend_worker:
            frontend_address: loki-query-frontend-headless:9095
          ingester:
            chunk_block_size: 262144
            chunk_encoding: snappy
            chunk_idle_period: 30m
            chunk_retain_period: 1m
            lifecycler:
              ring:
                kvstore:
                  store: memberlist
                replication_factor: 1
            wal:
              dir: /var/loki/wal
          ingester_client:
            grpc_client_config:
              grpc_compression: gzip
          limits_config:
            max_cache_freshness_per_query: 10m
            reject_old_samples: true
            reject_old_samples_max_age: 168h
            split_queries_by_interval: 15m
          memberlist:
            join_members:
            - loki-memberlist
          querier:
            engine:
              max_look_back_period: 0s
          query_range:
            align_queries_with_step: true
            cache_results: true
            max_retries: 5
            results_cache:
              cache:
                embedded_cache:
                  enabled: true
                  ttl: 24h
          ruler:
            ring:
              kvstore:
                store: memberlist
            rule_path: /tmp/loki/scratch
            storage:
              s3:
                bucketnames: loki-ruler
          runtime_config:
            file: /var/loki-runtime/runtime.yaml
          schema_config:
            configs:
            - from: "2023-01-05"
              index:
                period: 24h
                prefix: index_
              object_store: s3
              schema: v13
              store: tsdb
          server:
            http_listen_port: 3100
            http_listen_address: 0.0.0.0
          storage_config:
            aws:
              s3forcepathstyle: true
            tsdb_shipper:
              active_index_directory: /data/tsdb-index
              cache_location: /data/tsdb-cache
              cache_ttl: 24h
          table_manager:
            retention_deletes_enabled: false
            retention_period: 0s
        image:
          pullPolicy: Always
      serviceMonitor:
        enabled: true
      prometheusRule:
        enabled: true
        groups:
          - name: loki_rules
            rules:
              - expr: histogram_quantile(0.99, sum(rate(loki_request_duration_seconds_bucket[1m]))
                  by (le, cluster, job))
                record: cluster_job:loki_request_duration_seconds:99quantile
              - expr: histogram_quantile(0.50, sum(rate(loki_request_duration_seconds_bucket[1m]))
                  by (le, cluster, job))
                record: cluster_job:loki_request_duration_seconds:50quantile
              - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job) / sum(rate(loki_request_duration_seconds_count[1m]))
                  by (cluster, job)
                record: cluster_job:loki_request_duration_seconds:avg
              - expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, cluster, job)
                record: cluster_job:loki_request_duration_seconds_bucket:sum_rate
              - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job)
                record: cluster_job:loki_request_duration_seconds_sum:sum_rate
              - expr: sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, job)
                record: cluster_job:loki_request_duration_seconds_count:sum_rate
              - expr: histogram_quantile(0.99, sum(rate(loki_request_duration_seconds_bucket[1m]))
                  by (le, cluster, job, route))
                record: cluster_job_route:loki_request_duration_seconds:99quantile
              - expr: histogram_quantile(0.50, sum(rate(loki_request_duration_seconds_bucket[1m]))
                  by (le, cluster, job, route))
                record: cluster_job_route:loki_request_duration_seconds:50quantile
              - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job, route)
                  / sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, job, route)
                record: cluster_job_route:loki_request_duration_seconds:avg
              - expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, cluster, job,
                  route)
                record: cluster_job_route:loki_request_duration_seconds_bucket:sum_rate
              - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, job, route)
                record: cluster_job_route:loki_request_duration_seconds_sum:sum_rate
              - expr: sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, job, route)
                record: cluster_job_route:loki_request_duration_seconds_count:sum_rate
              - expr: histogram_quantile(0.99, sum(rate(loki_request_duration_seconds_bucket[1m]))
                  by (le, cluster, namespace, job, route))
                record: cluster_namespace_job_route:loki_request_duration_seconds:99quantile
              - expr: histogram_quantile(0.50, sum(rate(loki_request_duration_seconds_bucket[1m]))
                  by (le, cluster, namespace, job, route))
                record: cluster_namespace_job_route:loki_request_duration_seconds:50quantile
              - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, namespace,
                  job, route) / sum(rate(loki_request_duration_seconds_count[1m])) by (cluster,
                  namespace, job, route)
                record: cluster_namespace_job_route:loki_request_duration_seconds:avg
              - expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, cluster, namespace,
                  job, route)
                record: cluster_namespace_job_route:loki_request_duration_seconds_bucket:sum_rate
              - expr: sum(rate(loki_request_duration_seconds_sum[1m])) by (cluster, namespace,
                  job, route)
                record: cluster_namespace_job_route:loki_request_duration_seconds_sum:sum_rate
              - expr: sum(rate(loki_request_duration_seconds_count[1m])) by (cluster, namespace,
                  job, route)
                record: cluster_namespace_job_route:loki_request_duration_seconds_count:sum_rate
      ingester:
        kind: Deployment
        replicas: 1
        autoscaling:
          enabled: true
          minReplicas: 1
          maxReplicas: 3
        # persistence:
        #   enabled: true
        #   claims:
        #     - name: data
        #       size: 20Gi
        #       sotrageClass: longhorn
      querier:
        autoscaling:
          enabled: true
        # persistence:
        #   enabled: true
        #   size: 20Gi
        #   storageClass: longhorn
    tempo:
      nameOverride: tempo
      tempo:
        image:
          pullPolicy: Always
      fullnameOverride: tempo
      metricsGenerator:
        enabled: true
      traces:
        otlp:
          grpc:
            enabled: true
        jaeger:
          grpc:
            enabled: true
      storage:
        trace:
          backend: s3
          s3:
            bucket: tempo-traces
            endpoint: *s3_endpoint
            region: *s3_region
        admin:
          backend: s3
          s3:
            bucket: tempo-admin
            endpoint: *s3_endpoint
            region: *s3_region
