---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      version: 35.2.0
      sourceRef:
        kind: HelmRepository
        name: prometheus-community-charts
        namespace: flux-system
      interval: 5m
  install:
    createNamespace: true
    remediation:
      retries: 5
  upgrade:
    remediation:
      retries: 5
  values:
    alertmanager:
      config:
        global:
          resolve_timeout: 5m
        receivers:
          - name: "null"
        inhibit_rules:
          - source_matchers:
              - severity = "critical"
            target_matchers:
              - severity = "warning"
            equal: ["alertname", "namespace"]
      alertmanagerSpec:
        replicas: 2
        podAntiAffinity: hard
        storage:
          volumeClaimTemplate:
            spec:
              resources:
                requests:
                  storage: 10Gi
      prometheus:
        monitor:
          enabled: true
          relabelings:
            - action: replace
              regex: (.*)
              replacement: $1
              sourceLabels:
                - __meta_kubernetes_pod_node_name
              targetLabel: kubernetes_node
    prometheusOperator:
      createCustomResource: true
      prometheusConfigReloader:
        resources:
          requests:
            cpu: 150m
            memory: 50Mi
          limits:
            cpu: 300m
            memory: 50Mi
    nodeExporter:
      enabled: true
      serviceMonitor:
        relabelings:
          - action: replace
            regex: (.*)
            replacement: $1
            sourceLabels:
              - __meta_kubernetes_pod_node_name
            targetLabel: kubernetes_node
    kubelet:
      enabled: true
      serviceMonitor:
        metricRelabelings:
          - action: replace
            sourceLabels:
              - node
            targetLabel: instance
    grafana:
      # enabled: false
      defaultDashboardsTimezone: "America/New_York"
      dashboards:
        default:
          flux-cluster:
            url: https://raw.githubusercontent.com/fluxcd/flux2/main/manifests/monitoring/grafana/dashboards/cluster.json
            datasource: Prometheus
          flux-control-plane:
            url: https://raw.githubusercontent.com/fluxcd/flux2/main/manifests/monitoring/grafana/dashboards/control-plane.json
            datasource: Prometheus
      deploymentStrategy:
        type: Recreate
      persistence:
        enabled: false
      envFromSecret: "grafana-secrets"
      image:
        tag: 8.5.2
      plugins:
        - natel-discrete-panel
        - pr0ps-trackmap-panel
        - grafana-piechart-panel
        - vonage-status-panel
        - grafana-worldmap-panel
        - grafana-clock-panel
        - camptocamp-prometheus-alertmanager-datasource
        - cloudflare-app
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: "default"
              orgId: 1
              folder: ""
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/default
      sidecar:
        datasources:
          enabled: true
          defaultDatasourceEnabled: false
        dashboards:
          enabled: true
          searchNamespace: ALL
      additionalDataSources:
        - name: Prometheus
          type: prometheus
          access: proxy
          url: http://thanos-query:9090/
          isDefault: true
        - name: Alertmanager
          type: camptocamp-prometheus-alertmanager-datasource
          # type: alertmanager
          access: proxy
          url: http://alertmanager-operated:9093/
      ingress:
        enabled: false
      service:
        type: LoadBalancer
    kubeEtcd:
      enabled: false
    kubeControllerManager:
      enabled: true
    kubeScheduler:
      enabled: true
    kubeProxy:
      enabled: true
    prometheus:
      prometheusSpec:
        resources:
          requests:
            memory: 2000Mi
            cpu: 400m
          limits:
            memory: 6000Mi
        replicas: 2
        replicaExternalLabelName: "replica"
        podAntiAffinity: hard
        ruleSelector: {}
        ruleNamespaceSelector: {}
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        podMonitorNamespaceSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        retention: 2d
        retentionSize: "6GB"
        enableAdminAPI: true
        walCompression: true
        storageSpec:
          volumeClaimTemplate:
            spec:
              resources:
                requests:
                  storage: 10Gi
        thanos:
          image: quay.io/thanos/thanos:v0.26.0
          version: v0.25.2
          objectStorageConfig:
            name: thanos-secrets
            key: objstore.yml
        additionalScrapeConfigs:
          # - job_name: "opnsense"
          #   scrape_interval: 60s
          #   metrics_path: "/metrics"
          #   static_configs:
          #     - targets: ["${LOCAL_LAN_OPNSENSE}:9273"]
          #       labels:
          #         app: "opnsense"
          # - job_name: "truenas"
          #   scrape_interval: 60s
          #   metrics_path: "/metrics"
          #   static_configs:
          #     - targets: ["${LOCAL_LAN_TRUENAS}:9273"]
          #       labels:
          #         app: "truenas"
          # - job_name: "truenas-remote"
          #   scrape_interval: 60s
          #   metrics_path: "/metrics"
          #   static_configs:
          #     - targets: ["${LOCAL_LAN_TRUENAS_REMOTE}:9273"]
          #       labels:
          #         app: "truenas-remote"
          # Example scrape config for probing ingresses via the Blackbox Exporter.
          #
          # The relabeling allows the actual ingress scrape endpoint to be configured
          # via the following annotations:
          #
          # * `prometheus.io/probe`: Only probe ingresses that have a value of `true`
          # - job_name: "kubernetes-ingresses"
          #   metrics_path: /probe
          #   scrape_interval: 60s
          #   params:
          #     module: [http_2xx]
          #   kubernetes_sd_configs:
          #     - role: ingress
          #   relabel_configs:
          #     - source_labels:
          #         [__meta_kubernetes_ingress_annotation_prometheus_io_probe]
          #       action: keep
          #       regex: true
          #     - source_labels:
          #         [
          #           __meta_kubernetes_ingress_scheme,
          #           __address__,
          #           __meta_kubernetes_ingress_path,
          #         ]
          #       regex: (.+);(.+);(.+)
          #       replacement: ${1}://${2}${3}
          #       target_label: __param_target
          #     - target_label: __address__
          #       replacement: blackbox-exporter-prometheus-blackbox-exporter:9115
          #     - source_labels: [__param_target]
          #       target_label: instance
          #     - action: labelmap
          #       regex: __meta_kubernetes_ingress_label_(.+)
          #     - source_labels: [__meta_kubernetes_namespace]
          #       target_label: kubernetes_namespace
          #     - source_labels: [__meta_kubernetes_ingress_name]
          #       target_label: kubernetes_name
          - job_name: "kubernetes-services-http"
            metrics_path: /probe
            scrape_interval: 60s
            params:
              module: [http_2xx]
            kubernetes_sd_configs:
              - role: service
            relabel_configs:
              - source_labels:
                  [__meta_kubernetes_service_annotation_prometheus_io_probe]
                action: keep
                regex: true
              - source_labels:
                  [__meta_kubernetes_service_annotation_prometheus_io_protocol]
                action: keep
                regex: http
              - source_labels: [__address__]
                target_label: __param_target
              - target_label: __address__
                replacement: blackbox-exporter-prometheus-blackbox-exporter:9115
              - source_labels: [__param_target]
                target_label: instance
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                target_label: kubernetes_namespace
              - source_labels: [__meta_kubernetes_service_name]
                target_label: kubernetes_name
          - job_name: "kubernetes-services-tcp"
            metrics_path: /probe
            scrape_interval: 60s
            params:
              module: [tcp_connect]
            kubernetes_sd_configs:
              - role: service
            relabel_configs:
              - source_labels:
                  [__meta_kubernetes_service_annotation_prometheus_io_probe]
                action: keep
                regex: true
              - source_labels:
                  [__meta_kubernetes_service_annotation_prometheus_io_protocol]
                action: keep
                regex: tcp
              - source_labels: [__address__]
                target_label: __param_target
              - target_label: __address__
                replacement: blackbox-exporter-prometheus-blackbox-exporter:9115
              - source_labels: [__param_target]
                target_label: instance
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                target_label: kubernetes_namespace
              - source_labels: [__meta_kubernetes_service_name]
                target_label: kubernetes_name
      thanosService:
        enabled: true
      thanosServiceMonitor:
        enabled: true
      thanosIngress:
        enabled: false
